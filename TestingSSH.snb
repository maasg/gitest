{
  "metadata" : {
    "name" : "TestingSSH",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : {
      "xSparkVersion" : "1.6.1",
      "xWithParquet" : "false",
      "buildTime" : "Wed Jun 08 11:52:36 CEST 2016",
      "sparkNotebookVersion" : "0.7.0-SNAPSHOT",
      "xJlineDef" : "(org.scala-lang,2.10.5)",
      "scalaVersion" : "2.10.5",
      "sbtVersion" : "0.13.8",
      "formattedShaVersion" : "Some(8009cbac3656f9410823df1afa67f8b79dec102e-SNAPSHOT)",
      "xJets3tVersion" : "0.7.1",
      "xWithHive" : "false",
      "xHadoopVersion" : "2.2.0"
    },
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null
  },
  "cells" : [ {
    "metadata" : {
      "id" : "BDC42D19F254419E96FE449E52A10B37"
    },
    "cell_type" : "markdown",
    "source" : "## THIS is an SSH test"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "D8853EF19DBD461AB4864175484C0442"
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.streaming._\nimport org.apache.spark.streaming.dstream._",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.streaming._\nimport org.apache.spark.streaming.dstream._\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 4
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "B50B2781ACDB4AE488008741BACABA7C"
    },
    "cell_type" : "code",
    "source" : "val rdd = sparkContext.parallelize(1 to 10)\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:69\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "413F243652174FCB8BFB3599EB684572"
    },
    "cell_type" : "code",
    "source" : "val ssc = new StreamingContext(sparkContext, Seconds(1))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "ssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@2057accc\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "F7B03128112941F69556904B3A457A26"
    },
    "cell_type" : "code",
    "source" : "val dstream = new ConstantInputDStream(ssc,rdd)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "dstream: org.apache.spark.streaming.dstream.ConstantInputDStream[Int] = org.apache.spark.streaming.dstream.ConstantInputDStream@1b959aa5\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 7
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "0508C6BB73084802AE0D95F73444B42F"
    },
    "cell_type" : "code",
    "source" : "val t0= new Time(System.currentTimeMillis-1000)\nval d = dstream.slice(Seconds(1000), Seconds(2000))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "<console>:76: error: type mismatch;\n found   : org.apache.spark.streaming.Duration\n required: org.apache.spark.streaming.Time\n       val d = dstream.slice(Seconds(1000), Seconds(2000))\n                                    ^\n"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "8918506DD90245FB8F3F42443ECE7F31"
    },
    "cell_type" : "code",
    "source" : "\n",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}